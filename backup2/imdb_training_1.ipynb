{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100005 files belonging to 2 classes.\n",
      "Found 100005 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:56:04.630445: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 100005\n",
      "Example text: It's easy to forget, once later series had developed the alien conspiracy plot arc more, that once u...\n",
      "Example label: [1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "\n",
    "# Hides the GPU from TensorFlow\n",
    "tf.config.set_visible_devices([], 'GPU') \n",
    "\n",
    "# Base path for the dataset\n",
    "dataset_path = 'data/aclImdb'\n",
    "\n",
    "train_dataset = keras.utils.text_dataset_from_directory(os.path.expanduser(dataset_path), batch_size=50)    #batch size needs to be changed here\n",
    "valid_dataset = keras.utils.text_dataset_from_directory(os.path.expanduser(dataset_path), batch_size=50)    #batch size needs to be changed here\n",
    "\n",
    "\n",
    "# 1. Prepare text data from dataset\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for text_batch, label_batch in train_dataset:\n",
    "    for text, label in zip(text_batch.numpy(), label_batch.numpy()):\n",
    "        texts.append(text.decode('utf-8'))\n",
    "        labels.append([label]) # Convert to list for consistency\n",
    "\n",
    "print(f\"Number of training examples: {len(texts)}\")\n",
    "print(f\"Example text: {texts[0][:100]}...\")\n",
    "print(f\"Example label: {labels[0]}\")\n",
    "\n",
    "# 2. Tokenize and pad\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = np.array(labels)\n",
    "\n",
    "# After fitting the tokenizer\n",
    "# Save it\n",
    "with open(\"tokenizer1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Load GloVe embeddings\n",
    "embedding_dim = 50\n",
    "embeddings_index = {}\n",
    "\n",
    "glove_path = 'glove.6B.50d.txt'\n",
    "with open(glove_path, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    " \n",
    "# 4. Prepare embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(max_words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2501/2501 [==============================] - 33s 12ms/step - loss: 0.5696 - accuracy: 0.7492 - val_loss: 0.5620 - val_accuracy: 0.7519\n",
      "Epoch 2/10\n",
      "2501/2501 [==============================] - 29s 12ms/step - loss: 0.5650 - accuracy: 0.7495 - val_loss: 0.5599 - val_accuracy: 0.7519\n",
      "Epoch 3/10\n",
      "2501/2501 [==============================] - 29s 12ms/step - loss: 0.5632 - accuracy: 0.7495 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 4/10\n",
      "2501/2501 [==============================] - 34s 13ms/step - loss: 0.5607 - accuracy: 0.7495 - val_loss: 0.5593 - val_accuracy: 0.7519\n",
      "Epoch 5/10\n",
      "2501/2501 [==============================] - 41s 16ms/step - loss: 0.5580 - accuracy: 0.7495 - val_loss: 0.5594 - val_accuracy: 0.7519\n",
      "Epoch 6/10\n",
      "2501/2501 [==============================] - 46s 18ms/step - loss: 0.5528 - accuracy: 0.7495 - val_loss: 0.5628 - val_accuracy: 0.7519\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 50)           500000    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 98, 128)           19328     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 524001 (2.00 MB)\n",
      "Trainable params: 24001 (93.75 KB)\n",
      "Non-trainable params: 500000 (1.91 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CHANGE FROM HERE ONWARDS\n",
    "\n",
    "# 5. Build a simple model\n",
    "# this was the previous model initially in the file\n",
    "\"\"\"model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(max_len,)),\n",
    "    layers.Embedding(\n",
    "        input_dim=num_words,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False\n",
    "    ),\n",
    "    layers.Conv1D(64, 3, activation='relu'),  # Add local feature extraction\n",
    "    layers.GlobalMaxPooling1D(),  # Max pooling captures the most important features\n",
    "    layers.Dropout(0.2),  # Add regularization to prevent overfitting\n",
    "    layers.Dense(32, activation='relu'),  # Increase from 16 to 32\n",
    "    layers.Dense(16, activation='relu'),  # Add another layer\n",
    "    layers.Dropout(0.2),  # Additional dropout\n",
    "    layers.Dense(y.shape[1], activation='sigmoid')\n",
    "])\"\"\"\n",
    "\n",
    "# other model using CNN - the number of filters and kernel size should be tuned (maybe using a for loop)\n",
    "num_filters = 128  \n",
    "kernel_size = 3\n",
    "cnn_model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(max_len,)),\n",
    "    layers.Embedding(\n",
    "        input_dim=num_words,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False\n",
    "    ),\n",
    "    layers.Conv1D(num_filters, kernel_size, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(y shape[1], activation='softmax' if y.shape[1] > 2 else 'sigmoid')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy' if y.shape[1] > 2 else 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model = cnn_model  # Assign the chosen model to 'model'\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.fit(X, y, epochs=10, verbose=1, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "\"\"\"model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']  # Added AUC metric for better evaluation\n",
    ")\"\"\"\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# 6. Train\n",
    "#early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "#model.fit(X, y, epochs=10, verbose=1, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "# 6.B STORE MODEL\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is another alternative from some models used in the following paper: https://arxiv.org/pdf/1702.01923\n",
    "Here instead of 50 dimensions for the word embedding they use GloVe for 300 dimensions - their results of accuracy are good but here we are not achieving that performance - I only changed the batch size for the optimal size given in the paper for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 215ms/step - AUC: 0.4996 - Precision: 0.7496 - Recall: 0.9977 - accuracy: 0.7483 - loss: 0.5762 - val_AUC: 0.5006 - val_Precision: 0.7522 - val_Recall: 1.0000 - val_accuracy: 0.7522 - val_loss: 0.5623\n",
      "Epoch 2/10\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 120ms/step - AUC: 0.5015 - Precision: 0.7473 - Recall: 1.0000 - accuracy: 0.7473 - loss: 0.5696 - val_AUC: 0.5036 - val_Precision: 0.7522 - val_Recall: 1.0000 - val_accuracy: 0.7522 - val_loss: 0.5607\n",
      "Epoch 3/10\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 126ms/step - AUC: 0.5092 - Precision: 0.7465 - Recall: 1.0000 - accuracy: 0.7465 - loss: 0.5685 - val_AUC: 0.5004 - val_Precision: 0.7522 - val_Recall: 1.0000 - val_accuracy: 0.7522 - val_loss: 0.5608\n",
      "Epoch 4/10\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 123ms/step - AUC: 0.4998 - Precision: 0.7492 - Recall: 1.0000 - accuracy: 0.7492 - loss: 0.5650 - val_AUC: 0.4994 - val_Precision: 0.7522 - val_Recall: 1.0000 - val_accuracy: 0.7522 - val_loss: 0.5611\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">473,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m500,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m473,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m51,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,073,469</span> (7.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,073,469\u001b[0m (7.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">524,489</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m524,489\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,980</span> (4.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,048,980\u001b[0m (4.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other model using GRU alternative - according with the paper: Comparative Study of CNN and RNN for Natural Language Processing the ideal batch size is 50\n",
    "gru_units = 256\n",
    "gru_model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(max_len,)),\n",
    "    layers.Embedding(\n",
    "        input_dim=num_words,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False\n",
    "    ),\n",
    "    layers.SpatialDropout1D(0.2),  # Dropout for embeddings\n",
    "    layers.Bidirectional(layers.GRU(gru_units, return_sequences=False)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(y.shape[1], activation='sigmoid') \n",
    "])\n",
    "gru_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', 'AUC', 'Precision', 'Recall'])\n",
    "model = gru_model\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "model.fit(X, y, epochs=10, verbose=1, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('imdb_gru.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
