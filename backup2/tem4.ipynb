{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100005 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:06:12.303972: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I really think that Ms. Crawford (\"Eva Phillip...      1\n",
      "1  I missed the first 10 or so minutes of the mov...      1\n",
      "2  Thank goodness not all Dutch people are that r...      0\n",
      "3  I would like to start by saying I can only hop...      0\n",
      "4  I watched this a few days ago, so details are ...      1\n",
      "(100005, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Base path for the dataset\n",
    "dataset_path = 'data/aclImdb'\n",
    "\n",
    "valid_dataset = keras.utils.text_dataset_from_directory(os.path.expanduser(dataset_path), batch_size=32)    #batch size needs to be changed here\n",
    "\n",
    "# 1. Prepare text data from dataset\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for text_batch, label_batch in valid_dataset:\n",
    "    for text, label in zip(text_batch.numpy(), label_batch.numpy()):\n",
    "        texts.append(text.decode('utf-8'))\n",
    "        labels.append(label)\n",
    "\n",
    "# Create DataFrame\n",
    "validation_imdb = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(validation_imdb.head())\n",
    "print(validation_imdb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Initialize parameters\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('imdb_gru.keras')\n",
    "\n",
    "#7. Prediction Pipeline\n",
    "def prediction_pipeline(text, model, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    Pipeline function that handles all preprocessing steps and returns the sentiment.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to predict\n",
    "        model: Trained model\n",
    "        tokenizer: Tokenizer instance\n",
    "        max_len: Maximum sequence length\n",
    "    Returns:\n",
    "        str: Either \"positive\" or \"negative\" sentiment\n",
    "    \"\"\"\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded, verbose=0)[0][0]\n",
    "    return \"positive\" if prediction > 0.5 else \"negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply prediction pipeline to text column in batches for better performance\n",
    "batch_size = 32\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(validation_imdb), batch_size):\n",
    "    batch_texts = validation_imdb['text'].iloc[i:i+batch_size].tolist()\n",
    "    # Tokenize and pad the entire batch at once\n",
    "    sequences = tokenizer.texts_to_sequences(batch_texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    # Get predictions for the batch\n",
    "    batch_predictions = model.predict(padded, verbose=0)\n",
    "    # Convert probabilities to labels\n",
    "    batch_labels = ['positive' if pred > 0.5 else 'negative' for pred in batch_predictions]\n",
    "    predictions.extend(batch_labels)\n",
    "\n",
    "# Assign predictions to new column\n",
    "validation_imdb['pred_model_1'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tokens: [('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('br', 7), ('in', 8), ('it', 9), ('i', 10)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Make sure the file exists\n",
    "with open(\"tokenizer1.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"Top 10 tokens:\", list(tokenizer.word_index.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.legacy.preprocessing.text.Tokenizer at 0x163b2ea20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#7. Prediction Pipeline\n",
    "def prediction_pipeline2(text, model, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    Pipeline function that handles all preprocessing steps and returns the sentiment.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to predict\n",
    "        model: Trained model\n",
    "        tokenizer: Tokenizer instance\n",
    "        max_len: Maximum sequence length\n",
    "    Returns:\n",
    "        str: Either \"positive\" or \"negative\" sentiment\n",
    "    \"\"\"\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len)\n",
    "    print(sequence)\n",
    "    prediction = model.predict(padded, verbose=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7108332]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline2('FUCK THIS MOVIE', model, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 118, 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7222979]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline2('I LOVE THIS', model, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255, 17, 129]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7158122]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline2('WORST MOVIE EVER', model, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
